---
layout: post
title: What is an agent?
date: '2012-04-13T11:55:00.000+02:00'
author: Ondrej Platek
tags:
- School
- Virtual Beings
modified_time: '2012-07-23T17:16:05.250+02:00'
blogger_id: tag:blogger.com,1999:blog-1883852367990943689.post-1874850587820841883
blogger_orig_url: http://oplatek.blogspot.com/2012/04/what-is-agent.html
---

<h2> How to define agent?  </h2><br/>[Wooldridge, 1995]<br/><ul> <br/>    <li>reactivity</li><br/>    <li>proactiveness</li><br/>    <li>social ability</li><br/></ul><br/><br/>Questions: <br/><ul> <br/>    <li>thermostat, Unix demon( proactiveness-yes, reactivity- yes, social ability- not even by common agents:))</li><br/></ul><br/><br/>Remarks:<br/><ul> <br/>    <li>The abstraction we use if we want to think about agents</li><br/>    <li>Difference between UML object and agent? agent wants gain - money.... It is vague</li><br/>    <li>Important is goal of agent?</li><br/>    <li>Important is environment of agent, autonomous</li><br/></ul><br/><br/><h2> Belief - Desire - Intention (BDI) architecture </h2><br/><ul> <br/>    <li>Goal of BDI is to specify rational behaviour</li><br/>    <li>Belief - somehow the memory of an agent</li><br/>    <li>From Desires to Intentions - Intentions is thing we are working on, but they should be in contradiction</li><br/>    <li>desires: pass Exams, go to a party,   .... Intentions -Lets go to the party ( in order to be rational I can not do studying)</li><br/>    <li>Intentions should be persistent for some time: Granny is going to a sweet-shop, but she is not rational if she reconsider <br/>    the decisions on every step. However, reconsider it when she found out the the sweet-shop is closed is rational.</li><br/></ul><br/><br/><strong>Why the rationality should be defined like this: Bratman: Practical Reasoning</strong><br/><br/><h3> Languages implementing BDI </h3><br/><br/><ul> <br/>    <li>Jasson</li><br/>    <li>Goal</li><br/>    <li>....</li><br/>    <li>POSH - no so strict, but we are testing in our labs</li><br/></ul><br/><br/>POSH reminds <strong>behaviour trees</strong><br/><br/>Question is whether these languages are used in AI programming in Computer games industry<br/><br/><h3>  Game: <strong>Black and White</strong> </h3><br/><ul> <br/><li>Used BDI architecture</li><br/><li>The agents are learning</li><br/><li>AI game programming wisdom I chapter 11.2</li><br/><li><strong>Means-ends reasoning (CZE- analyza prostredku a cilu)</strong></li><br/><li>desire - Huger - Perceptron - User learns the agent to prefer eating why beeing sad/seeing food/low_energy</li><br/><li>The agent builds up simple decision trees</li><br/><li>Just reactive planner, no future Desires, Intentions</li><br/><li>BDI- Opinions(decisions tree)..in fact belongs to Belief section in BDI architecture, Belief(attribute list), Desires(perceptron), Intentions - planner choose the best plan (script) which satisfies our current desires</li><br/></ul><br/><br/>Comparison:<br/><ul> <br/>    <li>Tyrell architecture does similar thing with inhibiting other actions if first actions is choosen</li><br/></ul><br/><br/><h3> How to speed up <strong>if-then reles</strong>  </h3><br/><ul> <br/>    <li> does not recompute the already computed conditions from rules above </li><br/>    <li> evaluation - RETE (slides H-likeAgents8_Brom_060515.pdf )</li><br/>    <li> We have to able to QUICKLY evaluate if the atomic conditions CHANGED in current role</li><br/>    <li> In RETE could be the listeners(sth has changed) very expensive - <strong>they can be added on the fly</strong></li><br/></ul>